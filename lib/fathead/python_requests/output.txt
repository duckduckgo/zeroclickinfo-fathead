Binary Response Content	A										<p>You can also access the response body as bytes, for non-text requests:<pre>>>> r.content\nb'[{"repository":{"open_issues":0,"url":"https://github.com/...\n</pre> The gzip and deflate transfer-encodings are automatically decoded for you. For example, to create an image from binary data returned by a request, you can\nuse the following code:<pre>>>> from PIL import Image\n>>> from io import BytesIO\n\n>>> i = Image.open(BytesIO(r.content))\n</pre></p>	http://docs.python-requests.org/en/master/user/quickstart/#binary-response-content
Blocking Or Non-Blocking?	A										<p>With the default Transport Adapter in place, Requests does not provide any kind\nof non-blocking IO. The Response.content\nproperty will block until the entire response has been downloaded. If\nyou require more granularity, the streaming features of the library (see\nStreaming Requests) allow you to retrieve smaller quantities of the\nresponse at a time. However, these calls will still block. If you are concerned about the use of blocking IO, there are lots of projects\nout there that combine Requests with one of Python's asynchronicity frameworks.\nTwo excellent examples are grequests and requests-futures.</p>	http://docs.python-requests.org/en/master/user/advanced/#blocking-or-non-blocking
Body Content Workflow	A										<p>By default, when you make a request, the body of the response is downloaded\nimmediately. You can override this behaviour and defer downloading the response\nbody until you access the Response.content\nattribute with the stream parameter:<pre>tarball_url = 'https://github.com/kennethreitz/requests/tarball/master'\nr = requests.get(tarball_url, stream=True)\n</pre> At this point only the response headers have been downloaded and the connection\nremains open, hence allowing us to make content retrieval conditional:<pre>if int(r.headers['content-length']) < TOO_LONG:\n  content = r.content\n  ...\n</pre> You can further control the workflow by use of the Response.iter_content()\nand Response.iter_lines() methods.\nAlternatively, you can read the undecoded body from the underlying\nurllib3 urllib3.HTTPResponse at\nResponse.raw. If you set stream to True when making a request, Requests cannot\nrelease the connection back to the pool unless you consume all the data or call\nResponse.close. This can lead to\ninefficiency with connections. If you find yourself partially reading request\nbodies (or not reading them at all) while using stream=True, you should\nconsider using contextlib.closing (documented here), like this:<pre>from contextlib import closing\n\nwith closing(requests.get('http://httpbin.org/get', stream=True)) as r:\n    # Do things with the response here.\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#body-content-workflow
CA Certificates	A										<p>By default, Requests bundles a set of root CAs that it trusts, sourced from the\nMozilla trust store. However, these are only updated once for each Requests\nversion. This means that if you pin a Requests version your certificates can\nbecome extremely out of date. From Requests version 2.4.0 onwards, Requests will attempt to use certificates\nfrom certifi if it is present on the system. This allows for users to update\ntheir trusted certificates without having to change the code that runs on their\nsystem. For the sake of security we recommend upgrading certifi frequently!</p>	http://docs.python-requests.org/en/master/user/advanced/#ca-certificates
Chunk-Encoded Requests	A										<p>Requests also supports Chunked transfer encoding for outgoing and incoming requests.\nTo send a chunk-encoded request, simply provide a generator (or any iterator without\na length) for your body:<pre>def gen():\n    yield 'hi'\n    yield 'there'\n\nrequests.post('http://some.url/chunked', data=gen())\n</pre> For chunked encoded responses, it's best to iterate over the data using\nResponse.iter_content(). In\nan ideal situation you'll have set stream=True on the request, in which\ncase you can iterate chunk-by-chunk by calling iter_content with a chunk_size\nparameter of None. If you want to set a maximum size of the chunk,\nyou can set a chunk_size parameter to any integer.</p>	http://docs.python-requests.org/en/master/user/advanced/#chunk-encoded-requests
Compliance	A										<p>Requests is intended to be compliant with all relevant specifications and\nRFCs where that compliance will not cause difficulties for users. This\nattention to the specification can lead to some behaviour that may seem\nunusual to those not familiar with the relevant specification.</p>	http://docs.python-requests.org/en/master/user/advanced/#compliance
Cookies	A										<p>If a response contains some Cookies, you can quickly access them:<pre>>>> url = 'http://example.com/some/cookie/setting/url'\n>>> r = requests.get(url)\n\n>>> r.cookies['example_cookie_name']\n'example_cookie_value'\n</pre> To send your own cookies to the server, you can use the cookies\nparameter:<pre>>>> url = 'http://httpbin.org/cookies'\n>>> cookies = dict(cookies_are='working')\n\n>>> r = requests.get(url, cookies=cookies)\n>>> r.text\n'{"cookies": {"cookies_are": "working"}}'\n</pre> Cookies are returned in a RequestsCookieJar,\nwhich acts like a dict but also offers a more complete interface,\nsuitable for use over multiple domains or paths.  Cookie jars can\nalso be passed in to requests:<pre>>>> jar = requests.cookies.RequestsCookieJar()\n>>> jar.set('tasty_cookie', 'yum', site='httpbin.org', path='/cookies')\n>>> jar.set('gross_cookie', 'blech', site='httpbin.org', path='/elsewhere')\n>>> url = 'http://httpbin.org/cookies'\n>>> r = requests.get(url, cookies=jar)\n>>> r.text\n'{"cookies": {"tasty_cookie": "yum"}}'\n</pre></p>	http://docs.python-requests.org/en/master/user/quickstart/#cookies
Custom Authentication	A										<p>Requests allows you to use specify your own authentication mechanism. Any callable which is passed as the auth argument to a request method will\nhave the opportunity to modify the request before it is dispatched. Authentication implementations are subclasses of AuthBase,\nand are easy to define. Requests provides two common authentication scheme\nimplementations in requests.auth: HTTPBasicAuth and\nHTTPDigestAuth. Let's pretend that we have a web service that will only respond if the\nX-Pizza header is set to a password value. Unlikely, but just go with it.<pre>from requests.auth import AuthBase\n\nclass PizzaAuth(AuthBase):\n    """Attaches HTTP Pizza Authentication to the given Request object."""\n    def __init__(self, username):\n        # setup any auth-related data here\n        self.username = username\n\n    def __call__(self, r):\n        # modify and return the request\n        r.headers['X-Pizza'] = self.username\n        return r\n</pre> Then, we can make a request using our Pizza Auth:<pre>>>> requests.get('http://pizzabin.org/admin', auth=PizzaAuth('kenneth'))\n<Response [200]>\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#custom-authentication
Custom Headers	A										<p>If you'd like to add HTTP headers to a request, simply pass in a dict to the\nheaders parameter. For example, we didn't specify our user-agent in the previous example:<pre>>>> url = 'https://api.github.com/some/endpoint'\n>>> headers = {'user-agent': 'my-app/0.0.1'}\n\n>>> r = requests.get(url, headers=headers)\n</pre> Note: Custom headers are given less precedence than more specific sources of information. For instance: Furthermore, Requests does not change its behavior at all based on which custom headers are specified. The headers are simply passed on into the final request. Note: All header values must be a string, bytestring, or unicode. While permitted, it's advised to avoid passing unicode header values.</p>	http://docs.python-requests.org/en/master/user/quickstart/#custom-headers
Errors and Exceptions	A										<p>In the event of a network problem (e.g. DNS failure, refused connection, etc),\nRequests will raise a ConnectionError exception. Response.raise_for_status() will\nraise an HTTPError if the HTTP request\nreturned an unsuccessful status code. If a request times out, a Timeout exception is\nraised. If a request exceeds the configured number of maximum redirections, a\nTooManyRedirects exception is raised. All exceptions that Requests explicitly raises inherit from\nrequests.exceptions.RequestException. Ready for more? Check out the advanced section.</p>	http://docs.python-requests.org/en/master/user/quickstart/#errors-and-exceptions
Event Hooks	A										<p>Requests has a hook system that you can use to manipulate portions of\nthe request process, or signal event handling. Available hooks: You can assign a hook function on a per-request basis by passing a\n{hook_name: callback_function} dictionary to the hooks request\nparameter:<pre>hooks=dict(response=print_url)\n</pre> That callback_function will receive a chunk of data as its first\nargument.<pre>def print_url(r, *args, **kwargs):\n    print(r.url)\n</pre> If an error occurs while executing your callback, a warning is given. If the callback function returns a value, it is assumed that it is to\nreplace the data that was passed in. If the function doesn't return\nanything, nothing else is effected. Let's print some request method arguments at runtime:<pre>>>> requests.get('http://httpbin.org', hooks=dict(response=print_url))\nhttp://httpbin.org\n<Response [200]>\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#event-hooks
Header Ordering	A										<p>In unusual circumstances you may want to provide headers in an ordered manner. If you pass an OrderedDict to the headers keyword argument, that will provide the headers with an ordering. However, the ordering of the default headers used by Requests will be preferred, which means that if you override default headers in the headers keyword argument, they may appear out of order compared to other headers in that keyword argument. If this is problematic, users should consider setting the default headers on a Session object, by setting Session to a custom OrderedDict. That ordering will always be preferred.</p>	http://docs.python-requests.org/en/master/user/advanced/#header-ordering
HTTP Verbs	A										<p>Requests provides access to almost the full range of HTTP verbs: GET, OPTIONS,\nHEAD, POST, PUT, PATCH and DELETE. The following provides detailed examples of\nusing these various verbs in Requests, using the GitHub API. We will begin with the verb most commonly used: GET. HTTP GET is an idempotent\nmethod that returns a resource from a given URL. As a result, it is the verb\nyou ought to use when attempting to retrieve data from a web location. An\nexample usage would be attempting to get information about a specific commit\nfrom GitHub. Suppose we wanted commit a050faf on Requests. We would get it\nlike so:<pre>>>> import requests\n>>> r = requests.get('https://api.github.com/repos/kennethreitz/requests/git/commits/a050faf084662f3a352dd1a941f2c7c9f886d4ad')\n</pre> We should confirm that GitHub responded correctly. If it has, we want to work\nout what type of content it is. Do this like so:<pre>>>> if r.status_code == requests.codes.ok:\n...     print(r.headers['content-type'])\n...\napplication/json; charset=utf-8\n</pre> So, GitHub returns JSON. That's great, we can use the r.json method to parse it into Python objects.<pre>>>> commit_data = r.json()\n\n>>> print(commit_data.keys())\n[u'committer', u'author', u'url', u'tree', u'sha', u'parents', u'message']\n\n>>> print(commit_data[u'committer'])\n{u'date': u'2012-05-10T11:10:50-07:00', u'email': u'me@kennethreitz.com', u'name': u'Kenneth Reitz'}\n\n>>> print(commit_data[u'message'])\nmakin' history\n</pre> So far, so simple. Well, let's investigate the GitHub API a little bit. Now,\nwe could look at the documentation, but we might have a little more fun if we\nuse Requests instead. We can take advantage of the Requests OPTIONS verb to\nsee what kinds of HTTP methods are supported on the url we just used.<pre>>>> verbs = requests.options(r.url)\n>>> verbs.status_code\n500\n</pre> Uh, what? That's unhelpful! Turns out GitHub, like many API providers, don't\nactually implement the OPTIONS method. This is an annoying oversight, but it's\nOK, we can just use the boring documentation. If GitHub had correctly\nimplemented OPTIONS, however, they should return the allowed methods in the\nheaders, e.g.<pre>>>> verbs = requests.options('http://a-good-website.com/api/cats')\n>>> print(verbs.headers['allow'])\nGET,HEAD,POST,OPTIONS\n</pre> Turning to the documentation, we see that the only other method allowed for\ncommits is POST, which creates a new commit. As we're using the Requests repo,\nwe should probably avoid making ham-handed POSTS to it. Instead, let's play\nwith the Issues feature of GitHub. This documentation was added in response to\nIssue #482. Given that\nthis issue already exists, we will use it as an example. Let's start by getting it.<pre>>>> r = requests.get('https://api.github.com/repos/kennethreitz/requests/issues/482')\n>>> r.status_code\n200\n\n>>> issue = json.loads(r.text)\n\n>>> print(issue[u'title'])\nFeature any http verb in docs\n\n>>> print(issue[u'comments'])\n3\n</pre> Cool, we have three comments. Let's take a look at the last of them.<pre>>>> r = requests.get(r.url + u'/comments')\n>>> r.status_code\n200\n\n>>> comments = r.json()\n\n>>> print(comments[0].keys())\n[u'body', u'url', u'created_at', u'updated_at', u'user', u'id']\n\n>>> print(comments[2][u'body'])\nProbably in the "advanced" section\n</pre> Well, that seems like a silly place. Let's post a comment telling the poster\nthat he's silly. Who is the poster, anyway?<pre>>>> print(comments[2][u'user'][u'login'])\nkennethreitz\n</pre> OK, so let's tell this Kenneth guy that we think this example should go in the\nquickstart guide instead. According to the GitHub API doc, the way to do this\nis to POST to the thread. Let's do it.<pre>>>> body = json.dumps({u"body": u"Sounds great! I'll get right on it!"})\n>>> url = u"https://api.github.com/repos/kennethreitz/requests/issues/482/comments"\n\n>>> r = requests.post(url=url, data=body)\n>>> r.status_code\n404\n</pre> Huh, that's weird. We probably need to authenticate. That'll be a pain, right?\nWrong. Requests makes it easy to use many forms of authentication, including\nthe very common Basic Auth.<pre>>>> from requests.auth import HTTPBasicAuth\n>>> auth = HTTPBasicAuth('fake@example.com', 'not_a_real_password')\n\n>>> r = requests.post(url=url, data=body, auth=auth)\n>>> r.status_code\n201\n\n>>> content = r.json()\n>>> print(content[u'body'])\nSounds great! I'll get right on it.\n</pre> Brilliant. Oh, wait, no! I meant to add that it would take me a while, because\nI had to go feed my cat. If only I could edit this comment! Happily, GitHub\nallows us to use another HTTP verb, PATCH, to edit this comment. Let's do\nthat.<pre>>>> print(content[u"id"])\n5804413\n\n>>> body = json.dumps({u"body": u"Sounds great! I'll get right on it once I feed my cat."})\n>>> url = u"https://api.github.com/repos/kennethreitz/requests/issues/comments/5804413"\n\n>>> r = requests.patch(url=url, data=body, auth=auth)\n>>> r.status_code\n200\n</pre> Excellent. Now, just to torture this Kenneth guy, I've decided to let him\nsweat and not tell him that I'm working on this. That means I want to delete\nthis comment. GitHub lets us delete comments using the incredibly aptly named\nDELETE method. Let's get rid of it.<pre>>>> r = requests.delete(url=url, auth=auth)\n>>> r.status_code\n204\n>>> r.headers['status']\n'204 No Content'\n</pre> Excellent. All gone. The last thing I want to know is how much of my ratelimit\nI've used. Let's find out. GitHub sends that information in the headers, so\nrather than download the whole page I'll send a HEAD request to get the\nheaders.<pre>>>> r = requests.head(url=url, auth=auth)\n>>> print(r.headers)\n...\n'x-ratelimit-remaining': '4995'\n'x-ratelimit-limit': '5000'\n...\n</pre> Excellent. Time to write a Python program that abuses the GitHub API in all\nkinds of exciting ways, 4995 more times.</p>	http://docs.python-requests.org/en/master/user/advanced/#http-verbs
JSON Response Content	A										<p>There's also a builtin JSON decoder, in case you're dealing with JSON data:<pre>>>> import requests\n\n>>> r = requests.get('https://api.github.com/events')\n>>> r.json()\n[{u'repository': {u'open_issues': 0, u'url': 'https://github.com/...\n</pre> In case the JSON decoding fails, r.json() raises an exception. For example, if\nthe response gets a 204 (No Content), or if the response contains invalid JSON,\nattempting r.json() raises ValueError: No JSON object could be decoded. It should be noted that the success of the call to r.json() does not\nindicate the success of the response. Some servers may return a JSON object in a\nfailed response (e.g. error details with HTTP 500). Such JSON will be decoded\nand returned. To check that a request is successful, use\nr.raise_for_status() or check r.status_code is what you expect.</p>	http://docs.python-requests.org/en/master/user/quickstart/#json-response-content
Keep-Alive	A										<p>Excellent news — thanks to urllib3, keep-alive is 100% automatic within a session!\nAny requests that you make within a session will automatically reuse the appropriate\nconnection! Note that connections are only released back to the pool for reuse once all body\ndata has been read; be sure to either set stream to False or read the\ncontent property of the Response object.</p>	http://docs.python-requests.org/en/master/user/advanced/#keep-alive
Link Headers	A										<p>Many HTTP APIs feature Link headers. They make APIs more self describing and\ndiscoverable. GitHub uses these for pagination\nin their API, for example:<pre>>>> url = 'https://api.github.com/users/kennethreitz/repos?page=1&per_page=10'\n>>> r = requests.head(url=url)\n>>> r.headers['link']\n'<https://api.github.com/users/kennethreitz/repos?page=2&per_page=10>; rel="next", <https://api.github.com/users/kennethreitz/repos?page=6&per_page=10>; rel="last"'\n</pre> Requests will automatically parse these link headers and make them easily consumable:<pre>>>> r.links["next"]\n{'url': 'https://api.github.com/users/kennethreitz/repos?page=2&per_page=10', 'rel': 'next'}\n\n>>> r.links["last"]\n{'url': 'https://api.github.com/users/kennethreitz/repos?page=7&per_page=10', 'rel': 'last'}\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#link-headers
Make a Request	A										<p>Making a request with Requests is very simple. Begin by importing the Requests module:<pre>>>> import requests\n</pre> Now, let's try to get a webpage. For this example, let's get GitHub's public\ntimeline:<pre>>>> r = requests.get('https://api.github.com/events')\n</pre> Now, we have a Response object called r. We can\nget all the information we need from this object. Requests' simple API means that all forms of HTTP request are as obvious. For\nexample, this is how you make an HTTP POST request:<pre>>>> r = requests.post('http://httpbin.org/post', data = {'key':'value'})\n</pre> Nice, right? What about the other HTTP request types: PUT, DELETE, HEAD and\nOPTIONS? These are all just as simple:<pre>>>> r = requests.put('http://httpbin.org/put', data = {'key':'value'})\n>>> r = requests.delete('http://httpbin.org/delete')\n>>> r = requests.head('http://httpbin.org/get')\n>>> r = requests.options('http://httpbin.org/get')\n</pre> That's all well and good, but it's also only the start of what Requests can\ndo.</p>	http://docs.python-requests.org/en/master/user/quickstart/#make-a-request
More complicated POST requests	A										<p>Typically, you want to send some form-encoded data — much like an HTML form.\nTo do this, simply pass a dictionary to the data argument. Your\ndictionary of data will automatically be form-encoded when the request is made:<pre>>>> payload = {'key1': 'value1', 'key2': 'value2'}\n\n>>> r = requests.post("http://httpbin.org/post", data=payload)\n>>> print(r.text)\n{\n  ...\n  "form": {\n    "key2": "value2",\n    "key1": "value1"\n  },\n  ...\n}\n</pre> There are many times that you want to send data that is not form-encoded. If\nyou pass in a string instead of a dict, that data will be posted directly. For example, the GitHub API v3 accepts JSON-Encoded POST/PATCH data:<pre>>>> import json\n\n>>> url = 'https://api.github.com/some/endpoint'\n>>> payload = {'some': 'data'}\n\n>>> r = requests.post(url, data=json.dumps(payload))\n</pre> Instead of encoding the dict yourself, you can also pass it directly using\nthe json parameter (added in version 2.4.2) and it will be encoded automatically:<pre>>>> url = 'https://api.github.com/some/endpoint'\n>>> payload = {'some': 'data'}\n\n>>> r = requests.post(url, json=payload)\n</pre></p>	http://docs.python-requests.org/en/master/user/quickstart/#more-complicated-post-requests
Passing Parameters In URLs	A										<p>You often want to send some sort of data in the URL's query string. If\nyou were constructing the URL by hand, this data would be given as key/value\npairs in the URL after a question mark, e.g. httpbin.org/get?key=val.\nRequests allows you to provide these arguments as a dictionary, using the\nparams keyword argument. As an example, if you wanted to pass\nkey1=value1 and key2=value2 to httpbin.org/get, you would use the\nfollowing code:<pre>>>> payload = {'key1': 'value1', 'key2': 'value2'}\n>>> r = requests.get('http://httpbin.org/get', params=payload)\n</pre> You can see that the URL has been correctly encoded by printing the URL:<pre>>>> print(r.url)\nhttp://httpbin.org/get?key2=value2&key1=value1\n</pre> Note that any dictionary key whose value is None will not be added to the\nURL's query string. You can also pass a list of items as a value:<pre>>>> payload = {'key1': 'value1', 'key2': ['value2', 'value3']}\n\n>>> r = requests.get('http://httpbin.org/get', params=payload)\n>>> print(r.url)\nhttp://httpbin.org/get?key1=value1&key2=value2&key2=value3\n</pre></p>	http://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls
POST a Multipart-Encoded File	A										<p>Requests makes it simple to upload Multipart-encoded files:<pre>>>> url = 'http://httpbin.org/post'\n>>> files = {'file': open('report.xls', 'rb')}\n\n>>> r = requests.post(url, files=files)\n>>> r.text\n{\n  ...\n  "files": {\n    "file": "<censored...binary...data>"\n  },\n  ...\n}\n</pre> You can set the filename, content_type and headers explicitly:<pre>>>> url = 'http://httpbin.org/post'\n>>> files = {'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', {'Expires': '0'})}\n\n>>> r = requests.post(url, files=files)\n>>> r.text\n{\n  ...\n  "files": {\n    "file": "<censored...binary...data>"\n  },\n  ...\n}\n</pre> If you want, you can send strings to be received as files:<pre>>>> url = 'http://httpbin.org/post'\n>>> files = {'file': ('report.csv', 'some,data,to,send\nanother,row,to,send\n')}\n\n>>> r = requests.post(url, files=files)\n>>> r.text\n{\n  ...\n  "files": {\n    "file": "some,data,to,send\\nanother,row,to,send\\n"\n  },\n  ...\n}\n</pre> In the event you are posting a very large file as a multipart/form-data\nrequest, you may want to stream the request. By default, requests does not\nsupport this, but there is a separate package which does -\nrequests-toolbelt. You should read the toolbelt's documentation for more details about how to use it. For sending multiple files in one request refer to the advanced\nsection.</p>	http://docs.python-requests.org/en/master/user/quickstart/#post-a-multipart-encoded-file
POST Multiple Multipart-Encoded Files	A										<p>You can send multiple files in one request. For example, suppose you want to\nupload image files to an HTML form with a multiple file field 'images':<pre><input type="file" name="images" multiple="true" required="true"/>\n</pre> To do that, just set files to a list of tuples of (form_field_name, file_info):<pre>>>> url = 'http://httpbin.org/post'\n>>> multiple_files = [\n        ('images', ('foo.png', open('foo.png', 'rb'), 'image/png')),\n        ('images', ('bar.png', open('bar.png', 'rb'), 'image/png'))]\n>>> r = requests.post(url, files=multiple_files)\n>>> r.text\n{\n  ...\n  'files': {'images': 'data:image/png;base64,iVBORw ....'}\n  'Content-Type': 'multipart/form-data; boundary=3131623adb2043caaeb5538cc7aa0b3a',\n  ...\n}\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#post-multiple-multipart-encoded-files
Prepared Requests	A										<p>Whenever you receive a Response object\nfrom an API call or a Session call, the request attribute is actually the\nPreparedRequest that was used. In some cases you may wish to do some extra\nwork to the body or headers (or anything else really) before sending a\nrequest. The simple recipe for this is the following:<pre>from requests import Request, Session\n\ns = Session()\n\nreq = Request('POST', url, data=data, headers=headers)\nprepped = req.prepare()\n\n# do something with prepped.body\nprepped.body = 'No, I want exactly this as the body.'\n\n# do something with prepped.headers\ndel prepped.headers['Content-Type']\n\nresp = s.send(prepped,\n    stream=stream,\n    verify=verify,\n    proxies=proxies,\n    cert=cert,\n    timeout=timeout\n)\n\nprint(resp.status_code)\n</pre> Since you are not doing anything special with the Request object, you\nprepare it immediately and modify the PreparedRequest object. You then\nsend that with the other parameters you would have sent to requests.* or\nSession.*. However, the above code will lose some of the advantages of having a Requests\nSession object. In particular,\nSession-level state such as cookies will\nnot get applied to your request. To get a\nPreparedRequest with that state\napplied, replace the call to Request.prepare() with a call to\nSession.prepare_request(), like this:<pre>from requests import Request, Session\n\ns = Session()\nreq = Request('GET',  url, data=data, headers=headers)\n\nprepped = s.prepare_request(req)\n\n# do something with prepped.body\nprepped.body = 'Seriously, send exactly these bytes.'\n\n# do something with prepped.headers\nprepped.headers['Keep-Dead'] = 'parrot'\n\nresp = s.send(prepped,\n    stream=stream,\n    verify=verify,\n    proxies=proxies,\n    cert=cert,\n    timeout=timeout\n)\n\nprint(resp.status_code)\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#prepared-requests
Proxies	A										<p>If you need to use a proxy, you can configure individual requests with the\nproxies argument to any request method:<pre>import requests\n\nproxies = {\n  'http': 'http://10.10.1.10:3128',\n  'https': 'http://10.10.1.10:1080',\n}\n\nrequests.get('http://example.org', proxies=proxies)\n</pre> You can also configure proxies by setting the environment variables\nHTTP_PROXY and HTTPS_PROXY.<pre>$ export HTTP_PROXY="http://10.10.1.10:3128"\n$ export HTTPS_PROXY="http://10.10.1.10:1080"\n\n$ python\n>>> import requests\n>>> requests.get('http://example.org')\n</pre> To use HTTP Basic Auth with your proxy, use the http://user:password@host/ syntax:<pre>proxies = {'http': 'http://user:pass@10.10.1.10:3128/'}\n</pre> To give a proxy for a specific scheme and host, use the\nscheme://hostname form for the key.  This will match for\nany request to the given scheme and exact hostname.<pre>proxies = {'http://10.20.1.128': 'http://10.10.1.10:5323'}\n</pre> Note that proxy URLs must include the scheme.<pre>$ pip install requests[socks]\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#proxies
Raw Response Content	A										<p>In the rare case that you'd like to get the raw socket response from the\nserver, you can access r.raw. If you want to do this, make sure you set\nstream=True in your initial request. Once you do, you can do this:<pre>>>> r = requests.get('https://api.github.com/events', stream=True)\n\n>>> r.raw\n<requests.packages.urllib3.response.HTTPResponse object at 0x101194810>\n\n>>> r.raw.read(10)\n'\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03'\n</pre> In general, however, you should use a pattern like this to save what is being\nstreamed to a file:<pre>with open(filename, 'wb') as fd:\n    for chunk in r.iter_content(chunk_size):\n        fd.write(chunk)\n</pre> Using Response.iter_content will handle a lot of what you would otherwise\nhave to handle when using Response.raw directly. When streaming a\ndownload, the above is the preferred and recommended way to retrieve the\ncontent.</p>	http://docs.python-requests.org/en/master/user/quickstart/#raw-response-content
Redirection and History	A										<p>By default Requests will perform location redirection for all verbs except\nHEAD. We can use the history property of the Response object to track redirection. The Response.history list contains the\nResponse objects that were created in order to\ncomplete the request. The list is sorted from the oldest to the most recent\nresponse. For example, GitHub redirects all HTTP requests to HTTPS:<pre>>>> r = requests.get('http://github.com')\n\n>>> r.url\n'https://github.com/'\n\n>>> r.status_code\n200\n\n>>> r.history\n[<Response [301]>]\n</pre> If you're using GET, OPTIONS, POST, PUT, PATCH or DELETE, you can disable\nredirection handling with the allow_redirects parameter:<pre>>>> r = requests.get('http://github.com', allow_redirects=False)\n\n>>> r.status_code\n301\n\n>>> r.history\n[]\n</pre> If you're using HEAD, you can enable redirection as well:<pre>>>> r = requests.head('http://github.com', allow_redirects=True)\n\n>>> r.url\n'https://github.com/'\n\n>>> r.history\n[<Response [301]>]\n</pre></p>	http://docs.python-requests.org/en/master/user/quickstart/#redirection-and-history
Request and Response Objects	A										<p>Whenever a call is made to requests.get() and friends, you are doing two\nmajor things. First, you are constructing a Request object which will be\nsent off to a server to request or query some resource. Second, a Response\nobject is generated once Requests gets a response back from the server.\nThe Response object contains all of the information returned by the server and\nalso contains the Request object you created originally. Here is a simple\nrequest to get some very important information from Wikipedia's servers:<pre>>>> r = requests.get('http://en.wikipedia.org/wiki/Monty_Python')\n</pre> If we want to access the headers the server sent back to us, we do this:<pre>>>> r.headers\n{'content-length': '56170', 'x-content-type-options': 'nosniff', 'x-cache':\n'HIT from cp1006.eqiad.wmnet, MISS from cp1010.eqiad.wmnet', 'content-encoding':\n'gzip', 'age': '3080', 'content-language': 'en', 'vary': 'Accept-Encoding,Cookie',\n'server': 'Apache', 'last-modified': 'Wed, 13 Jun 2012 01:33:50 GMT',\n'connection': 'close', 'cache-control': 'private, s-maxage=0, max-age=0,\nmust-revalidate', 'date': 'Thu, 14 Jun 2012 12:59:39 GMT', 'content-type':\n'text/html; charset=UTF-8', 'x-cache-lookup': 'HIT from cp1006.eqiad.wmnet:3128,\nMISS from cp1010.eqiad.wmnet:80'}\n</pre> However, if we want to get the headers we sent the server, we simply access the\nrequest, and then the request's headers:<pre>>>> r.request.headers\n{'Accept-Encoding': 'identity, deflate, compress, gzip',\n'Accept': '*/*', 'User-Agent': 'python-requests/1.2.0'}\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#request-and-response-objects
Response Content	A										<p>We can read the content of the server's response. Consider the GitHub timeline\nagain:<pre>>>> import requests\n\n>>> r = requests.get('https://api.github.com/events')\n>>> r.text\nu'[{"repository":{"open_issues":0,"url":"https://github.com/...\n</pre> Requests will automatically decode content from the server. Most unicode\ncharsets are seamlessly decoded. When you make a request, Requests makes educated guesses about the encoding of\nthe response based on the HTTP headers. The text encoding guessed by Requests\nis used when you access r.text. You can find out what encoding Requests is\nusing, and change it, using the r.encoding property:<pre>>>> r.encoding\n'utf-8'\n>>> r.encoding = 'ISO-8859-1'\n</pre> If you change the encoding, Requests will use the new value of r.encoding\nwhenever you call r.text. You might want to do this in any situation where\nyou can apply special logic to work out what the encoding of the content will\nbe. For example, HTTP and XML have the ability to specify their encoding in\ntheir body. In situations like this, you should use r.content to find the\nencoding, and then set r.encoding. This will let you use r.text with\nthe correct encoding. Requests will also use custom encodings in the event that you need them. If\nyou have created your own encoding and registered it with the codecs\nmodule, you can simply use the codec name as the value of r.encoding and\nRequests will handle the decoding for you.</p>	http://docs.python-requests.org/en/master/user/quickstart/#response-content
Response Headers	A										<p>We can view the server's response headers using a Python dictionary:<pre>>>> r.headers\n{\n    'content-encoding': 'gzip',\n    'transfer-encoding': 'chunked',\n    'connection': 'close',\n    'server': 'nginx/1.0.4',\n    'x-runtime': '148ms',\n    'etag': '"e1ca502697e5c9317743dc078f67693f"',\n    'content-type': 'application/json'\n}\n</pre> The dictionary is special, though: it's made just for HTTP headers. According to\nRFC 7230, HTTP Header names\nare case-insensitive. So, we can access the headers using any capitalization we want:<pre>>>> r.headers['Content-Type']\n'application/json'\n\n>>> r.headers.get('content-type')\n'application/json'\n</pre> It is also special in that the server could have sent the same header multiple\ntimes with different values, but requests combines them so they can be\nrepresented in the dictionary within a single mapping, as per\nRFC 7230:</p>	http://docs.python-requests.org/en/master/user/quickstart/#response-headers
Response Status Codes	A										<p>We can check the response status code:<pre>>>> r = requests.get('http://httpbin.org/get')\n>>> r.status_code\n200\n</pre> Requests also comes with a built-in status code lookup object for easy\nreference:<pre>>>> r.status_code == requests.codes.ok\nTrue\n</pre> If we made a bad request (a 4XX client error or 5XX server error response), we\ncan raise it with\nResponse.raise_for_status():<pre>>>> bad_r = requests.get('http://httpbin.org/status/404')\n>>> bad_r.status_code\n404\n\n>>> bad_r.raise_for_status()\nTraceback (most recent call last):\n  File "requests/models.py", line 832, in raise_for_status\n    raise http_error\nrequests.exceptions.HTTPError: 404 Client Error\n</pre> But, since our status_code for r was 200, when we call\nraise_for_status() we get:<pre>>>> r.raise_for_status()\nNone\n</pre> All is well.</p>	http://docs.python-requests.org/en/master/user/quickstart/#response-status-codes
Session Objects	A										<p>The Session object allows you to persist certain parameters across\nrequests. It also persists cookies across all requests made from the\nSession instance, and will use urllib3's connection pooling. So if\nyou're making several requests to the same host, the underlying TCP\nconnection will be reused, which can result in a significant performance\nincrease (see HTTP persistent connection). A Session object has all the methods of the main Requests API. Let's persist some cookies across requests:<pre>s = requests.Session()\n\ns.get('http://httpbin.org/cookies/set/sessioncookie/123456789')\nr = s.get('http://httpbin.org/cookies')\n\nprint(r.text)\n# '{"cookies": {"sessioncookie": "123456789"}}'\n</pre> Sessions can also be used to provide default data to the request methods. This\nis done by providing data to the properties on a Session object:<pre>s = requests.Session()\ns.auth = ('user', 'pass')\ns.headers.update({'x-test': 'true'})\n\n# both 'x-test' and 'x-test2' are sent\ns.get('http://httpbin.org/headers', headers={'x-test2': 'true'})\n</pre> Any dictionaries that you pass to a request method will be merged with the\nsession-level values that are set. The method-level parameters override session\nparameters. Note, however, that method-level parameters will not be persisted across\nrequests, even if using a session. This example will only send the cookies\nwith the first request, but not the second:<pre>s = requests.Session()\n\nr = s.get('http://httpbin.org/cookies', cookies={'from-my': 'browser'})\nprint(r.text)\n# '{"cookies": {"from-my": "browser"}}'\n\nr = s.get('http://httpbin.org/cookies')\nprint(r.text)\n# '{"cookies": {}}'\n</pre> If you want to manually add cookies to your session, use the\nCookie utility functions to manipulate\nSession.cookies. Sessions can also be used as context managers:<pre>with requests.Session() as s:\n    s.get('http://httpbin.org/cookies/set/sessioncookie/123456789')\n</pre> This will make sure the session is closed as soon as the with block is\nexited, even if unhandled exceptions occurred. All values that are contained within a session are directly available to you.\nSee the Session API Docs to learn more.</p>	http://docs.python-requests.org/en/master/user/advanced/#session-objects
SSL Cert Verification	A										<p>Requests verifies SSL certificates for HTTPS requests, just like a web browser.\nBy default, SSL verification is enabled, and Requests will throw a SSLError if\nit's unable to verify the certificate:<pre>>>> requests.get('https://requestb.in')\nrequests.exceptions.SSLError: hostname 'requestb.in' doesn't match either of '*.herokuapp.com', 'herokuapp.com'\n</pre> I don't have SSL setup on this domain, so it throws an exception. Excellent. GitHub does though:<pre>>>> requests.get('https://github.com')\n<Response [200]>\n</pre> You can pass verify the path to a CA_BUNDLE file or directory with certificates of trusted CAs:<pre>>>> requests.get('https://github.com', verify='/path/to/certfile')\n</pre> or persistent:<pre>s = requests.Session()\ns.verify = '/path/to/certfile'\n</pre> This list of trusted CAs can also be specified through the REQUESTS_CA_BUNDLE environment variable. Requests can also ignore verifying the SSL certificate if you set verify to False:<pre>>>> requests.get('https://kennethreitz.com', verify=False)\n<Response [200]>\n</pre> By default, verify is set to True. Option verify only applies to host certs. You can also specify a local cert to use as client side certificate, as a single\nfile (containing the private key and the certificate) or as a tuple of both\nfile's path:<pre>>>> requests.get('https://kennethreitz.com', cert=('/path/client.cert', '/path/client.key'))\n<Response [200]>\n</pre> or persistent:<pre>s = requests.Session()\ns.cert = '/path/client.cert'\n</pre> If you specify a wrong path or an invalid cert, you'll get a SSLError:<pre>>>> requests.get('https://kennethreitz.com', cert='/wrong_path/client.pem')\nSSLError: [Errno 336265225] _ssl.c:347: error:140B0009:SSL routines:SSL_CTX_use_PrivateKey_file:PEM lib\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#ssl-cert-verification
Streaming Requests	A										<p>With Response.iter_lines() you can easily\niterate over streaming APIs such as the Twitter Streaming\nAPI. Simply\nset stream to True and iterate over the response with\niter_lines:<pre>import json\nimport requests\n\nr = requests.get('http://httpbin.org/stream/20', stream=True)\n\nfor line in r.iter_lines():\n\n    # filter out keep-alive new lines\n    if line:\n        print(json.loads(line))\n</pre><pre>lines = r.iter_lines()\n# Save the first line for later or just skip it\n\nfirst_line = next(lines)\n\nfor line in lines:\n    print(line)\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#streaming-requests
Streaming Uploads	A										<p>Requests supports streaming uploads, which allow you to send large streams or\nfiles without reading them into memory. To stream and upload, simply provide a\nfile-like object for your body:<pre>with open('massive-body', 'rb') as f:\n    requests.post('http://some.url/streamed', data=f)\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#streaming-uploads
Timeouts	A										<p>Most requests to external servers should have a timeout attached, in case the\nserver is not responding in a timely manner. By default, requests do not time\nout unless a timeout value is set explicitly. Without a timeout, your code may\nhang for minutes or more. The connect timeout is the number of seconds Requests will wait for your\nclient to establish a connection to a remote machine (corresponding to the\nconnect()) call on the socket. It's a good practice to set connect timeouts\nto slightly larger than a multiple of 3, which is the default TCP packet\nretransmission window. Once your client has connected to the server and sent the HTTP request, the\nread timeout is the number of seconds the client will wait for the server\nto send a response. (Specifically, it's the number of seconds that the client\nwill wait between bytes sent from the server. In 99.9% of cases, this is the\ntime before the server sends the first byte). If you specify a single value for the timeout, like this:<pre>r = requests.get('https://github.com', timeout=5)\n</pre> The timeout value will be applied to both the connect and the read\ntimeouts. Specify a tuple if you would like to set the values separately:<pre>r = requests.get('https://github.com', timeout=(3.05, 27))\n</pre> If the remote server is very slow, you can tell Requests to wait forever for\na response, by passing None as a timeout value and then retrieving a cup of\ncoffee.<pre>r = requests.get('https://github.com', timeout=None)\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#timeouts
Timeouts	A										<p>You can tell Requests to stop waiting for a response after a given number of\nseconds with the timeout parameter:<pre>>>> requests.get('http://github.com', timeout=0.001)\nTraceback (most recent call last):\n  File "<stdin>", line 1, in <module>\nrequests.exceptions.Timeout: HTTPConnectionPool(host='github.com', port=80): Request timed out. (timeout=0.001)\n</pre></p>	http://docs.python-requests.org/en/master/user/quickstart/#timeouts
Transport Adapters	A										<p>As of v1.0.0, Requests has moved to a modular internal design. Part of the\nreason this was done was to implement Transport Adapters, originally\ndescribed here. Transport Adapters provide a mechanism to define interaction\nmethods for an HTTP service. In particular, they allow you to apply per-service\nconfiguration. Requests ships with a single Transport Adapter, the HTTPAdapter. This adapter provides the default Requests\ninteraction with HTTP and HTTPS using the powerful urllib3 library. Whenever\na Requests Session is initialized, one of these is\nattached to the Session object for HTTP, and one\nfor HTTPS. Requests enables users to create and use their own Transport Adapters that\nprovide specific functionality. Once created, a Transport Adapter can be\nmounted to a Session object, along with an indication of which web services\nit should apply to.<pre>>>> s = requests.Session()\n>>> s.mount('http://www.github.com', MyAdapter())\n</pre> The mount call registers a specific instance of a Transport Adapter to a\nprefix. Once mounted, any HTTP request made using that session whose URL starts\nwith the given prefix will use the given Transport Adapter. Many of the details of implementing a Transport Adapter are beyond the scope of\nthis documentation, but take a look at the next example for a simple SSL use-\ncase. For more than that, you might look at subclassing the\nBaseAdapter.<pre>import ssl\n\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.poolmanager import PoolManager\n\n\nclass Ssl3HttpAdapter(HTTPAdapter):\n    """"Transport adapter" that allows us to use SSLv3."""\n\n    def init_poolmanager(self, connections, maxsize, block=False):\n        self.poolmanager = PoolManager(\n            num_pools=connections, maxsize=maxsize,\n            block=block, ssl_version=ssl.PROTOCOL_SSLv3)\n</pre></p>	http://docs.python-requests.org/en/master/user/advanced/#transport-adapters
